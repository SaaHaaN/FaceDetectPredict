{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costum Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset sÄ±nÄ±fÄ±\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, class_to_idx=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = class_to_idx  # Burada class_to_idx'yi alÄ±yoruz\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# KlasÃ¶rlerden resimleri ve etiketleri almak iÃ§in fonksiyon\n",
    "def get_image_paths_and_labels(root_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(root_dir))  # alt klasÃ¶r isimleri -> sÄ±nÄ±f\n",
    "    class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}  # SÄ±nÄ±f -> indeks\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(root_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for img_path in glob(os.path.join(class_path, '*')):\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(class_to_idx[class_name])  # SÄ±nÄ±fÄ±n indeksini etiket olarak ekle\n",
    "        \n",
    "    return image_paths, labels, class_to_idx  # class_to_idx'yi dÃ¶ndÃ¼r\n",
    "\n",
    "\n",
    "# Transformlar\n",
    "transformsForTrain = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transformsForVal = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transformsForTest = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# KlasÃ¶r yollarÄ±\n",
    "train_dir = 'Your_train_directory_path_here'  # EÄŸitim seti klasÃ¶r yolu\n",
    "val_dir = 'Your_val_directory_path_here'      # DoÄŸrulama seti klasÃ¶r yolu\n",
    "test_dir = 'Your_test_directory_path_here'    # Test seti klasÃ¶r yolu\n",
    "\n",
    "# EÄŸitim seti\n",
    "train_image_paths, train_labels, train_class_to_idx = get_image_paths_and_labels(train_dir)\n",
    "train_data = CustomImageDataset(train_image_paths, train_labels, class_to_idx=train_class_to_idx, transform=transformsForTrain)\n",
    "\n",
    "# DoÄŸrulama seti\n",
    "val_image_paths, val_labels, val_class_to_idx = get_image_paths_and_labels(val_dir)\n",
    "val_data = CustomImageDataset(val_image_paths, val_labels, class_to_idx=val_class_to_idx, transform=transformsForVal)\n",
    "\n",
    "# Test seti\n",
    "test_image_paths, test_labels, test_class_to_idx = get_image_paths_and_labels(test_dir)\n",
    "test_data = CustomImageDataset(test_image_paths, test_labels, class_to_idx=test_class_to_idx, transform=transformsForTest)\n",
    "\n",
    "\n",
    "# DataLoader oluÅŸturma\n",
    "bs = 32\n",
    "train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=bs, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=bs, shuffle=False)\n",
    "\n",
    "# EÄŸitim, doÄŸrulama ve test verisinin toplam uzunluÄŸunu yazdÄ±r\n",
    "print(\"Total images in train dataset:\", len(train_data))\n",
    "print(\"Total images in validation dataset:\", len(val_data))\n",
    "print(\"Total images in test dataset:\", len(test_data))\n",
    "\n",
    "# class_to_idx'yi kontrol etme\n",
    "print(\"class_to_idx for train dataset:\", train_class_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SÄ±nÄ±f AdlarÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(test_loader.dataset.class_to_idx.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SÄ±nÄ±f SayÄ±sÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(train_labels))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model OluÅŸumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet50Model(num_classes):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    print(\"Model created successfully\")\n",
    "    return model.to(device)\n",
    "\n",
    "num_classes = len(train_class_to_idx)\n",
    "model = Resnet50Model(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=10):\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n{'=' * 40}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"{'=' * 40}\")\n",
    "        \n",
    "        # EÄŸitim\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        \n",
    "        print(f\"[Train] Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "        # DoÄŸrulama\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"[Val]   Loss: {val_loss:.4f} | Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # En iyi modeli kaydetme\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'FaceDetection_best.pth')\n",
    "            print(f\"âœ… Best model saved (Val Loss: {val_loss:.4f})\")\n",
    "\n",
    "    # Son modeli kaydet\n",
    "    torch.save(model.state_dict(), 'FaceDetection_last.pth')\n",
    "    print(\"\\nðŸŽ‰ Training completed. Final model saved as 'FaceDetection_last.pth'\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train AÅŸamasÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test AÅŸamasÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Resnet50Model(num_classes)\n",
    "model.load_state_dict(torch.load('FaceDetection_best.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Test iÅŸlemi iÃ§in deÄŸiÅŸkenleri baÅŸlat\n",
    "test_running_loss, test_running_corrects = 0.0, 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Test iÅŸlemi (Evaluation)\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_running_loss / len(test_loader.dataset)\n",
    "test_acc = test_running_corrects.double() / len(test_loader.dataset)\n",
    "\n",
    "print(f\"âœ… Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "class_names = list(test_loader.dataset.class_to_idx.keys())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Tahmin Edilen Etiket\")\n",
    "plt.ylabel(\"GerÃ§ek Etiket\")\n",
    "plt.title(f\"Confusion Matrix\\nTest Accuracy: {test_acc:.4f}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rastgele 10 test gÃ¶rÃ¼ntÃ¼sÃ¼ ve tahminleri gÃ¶rselleÅŸtir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 10 rastgele Ã¶rnek seÃ§\n",
    "random_indices = random.sample(range(len(test_data)), 10)\n",
    "images, labels = zip(*[test_data[i] for i in random_indices])\n",
    "\n",
    "# Batch'i tek bir tensor olarak birleÅŸtir\n",
    "images = torch.stack(images)  # Tensor'u birleÅŸtir\n",
    "\n",
    "# Modeli tahmin yapmak iÃ§in kullan\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images.to(device))\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "# GÃ¶rselleri ve tahminleri gÃ¶ster\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# GÃ¶rselleri sÄ±rayla yerleÅŸtir\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)  # 2 satÄ±r, 5 sÃ¼tunlu bir Ä±zgara\n",
    "    image = images[i].permute(1, 2, 0).cpu().numpy()  # Tensor'u numpy array'e Ã§evir\n",
    "    image = np.clip(image, 0, 1)  # GÃ¶rÃ¼ntÃ¼yÃ¼ normalleÅŸtir\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    # GerÃ§ek etiket ve tahmin edilen etiket\n",
    "    true_label = labels[i]\n",
    "    predicted_label = preds[i]\n",
    "    \n",
    "    # BaÅŸlÄ±k kÄ±smÄ±nÄ± dÃ¼zenle\n",
    "    plt.title(f\"True: {class_names[true_label]}\\nPred: {class_names[predicted_label]}\", fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "# GÃ¶rsellerin dÃ¼zgÃ¼n ÅŸekilde hizalanmasÄ± ve boÅŸluklarÄ±n artÄ±rÄ±lmasÄ±\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YÃ¼z tanÄ±ma iÃ§in OpenCV kullanarak yÃ¼z tespiti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle\n",
    "img = cv2.imread('X.jpg') # Herhangi bir gÃ¶rÃ¼ntÃ¼ dosyasÄ±nÄ± yÃ¼kleyebilirsiniz\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# OpenCV'nin hazÄ±r yÃ¼z dedektÃ¶rÃ¼nÃ¼ yÃ¼kle\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# YÃ¼zleri tespit et\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# YÃ¼zlerin etrafÄ±na kutu Ã§iz\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Sonucu gÃ¶ster\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model ile yÃ¼z tespiti birlikte, yÃ¼zÃ¼n etrafÄ±na bir dikdÃ¶rtgen Ã§izeceÄŸiz.\n",
    "### YÃ¼z tespiti iÃ§in ise eÄŸittiÄŸimiz modelin aÄŸÄ±rlÄ±klarÄ±nÄ± kullanacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Cihaz seÃ§imi\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Modeli oluÅŸtur ve yÃ¼kle\n",
    "model = Resnet50Model(num_classes)\n",
    "model.load_state_dict(torch.load('FaceDetection_best.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# SÄ±nÄ±f isimleri\n",
    "class_names = ['Female', 'Male']\n",
    "\n",
    "# MTCNN ile yÃ¼z tespiti\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "# GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle (PIL formatÄ±)\n",
    "img = Image.open('X.jpg') # Herhangi bir resim dosyasÄ±nÄ± buraya koyabilirsiniz\n",
    "plt.imshow(img)\n",
    "\n",
    "\n",
    "# YÃ¼zleri tespit et\n",
    "boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "# GÃ¶rÃ¼ntÃ¼yÃ¼ numpy olarak kopyala (cv2 iÃ§in)\n",
    "#img_np = np.array(img)\n",
    "img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "img_copy = img_np.copy()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Her yÃ¼z iÃ§in sÄ±nÄ±flandÄ±rma\n",
    "if boxes is not None:\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        face = img.crop((x1, y1, x2, y2))\n",
    "        face_tensor = transform(face).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(face_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            label = class_names[predicted.item()]\n",
    "\n",
    "        # Kutuyu Ã§iz ve etiketle\n",
    "        cv2.rectangle(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img_copy, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "# SonuÃ§ gÃ¶ster\n",
    "plt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
